{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289c4917",
   "metadata": {},
   "source": [
    "# Optimizing Revenue through Price Point Selection for Microtransactions\n",
    "\n",
    "**Objective:** The core objective of this project is to harness the power of A/B testing for determining the most effective price point for a newly launched feature on the FarmBurg platform. This determination is crucial for ensuring the profitability and sustainability of the feature.\n",
    "\n",
    "Brian, the proprietor of FarmBurg, has implemented an A/B test involving three distinct groups, denoted as 'A', 'B', and 'C'. Each group was presented with a different price point for the new feature, \\\\$0.99, \\\\$1.99, and \\\\$4.99 respectively.\n",
    "\n",
    "> Note: during the initial stages of my analysis, I investigate the purchasing behaviors across the groups with the underlying assumption that all groups were presented with the same price. This detail is considered later, particularly when I conduct the chi-square test and determine the appropriate hypothesis tests to utilize at each step of my analysis afterwards.\n",
    "\n",
    "My aim is to ensure that this new feature contributes at least \\\\$1,000 weekly towards the platform's revenue. Brian, the owner of the platform, has specified this amount as the baseline revenue needed to cover the costs associated with the feature's development and continuous maintenance\n",
    "\n",
    "Data: The dataset, 'clicks.csv', includes:\n",
    "\n",
    "- `user_id`: a unique id for each visitor\n",
    "- `group`: the group to which the visitor was assigned (A, B, or C)\n",
    "- `is_purchase`: whether the visitor made a purchase (Yes or No)\n",
    "\n",
    "**Outcome:** Based on the analysis, which price point should Brian choose for the new feature to maximize the chances of meeting or exceeding the target weekly revenue?'\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data Loading and Initial Inspection\n",
    "\n",
    "The first step of my analysis is to load the provided data and perform an initial inspection. The data comes from a CSV file named clicks.csv and includes the following columns:\n",
    "\n",
    "    `user_id`: A unique id for each visitor to the FarmBurg site.\n",
    "    `group`: Indicates the group (A, B, or C) to which the visitor was assigned.\n",
    "    `is_purchase`: Specifies whether the visitor made a purchase (Yes) or not (No).\n",
    "\n",
    "I will load this data into a pandas DataFrame and use the head() method to display the first few rows. This will give a sense of the data structure and allow me to confirm that the data has been loaded correctly.\n",
    "\n",
    "> Note: I am using the pandas library to load and manipulate the data. The numpy library will be used for numerical operations, while the scipy.stats library will be used for statistical tests.\n",
    "\n",
    "Question: Are all sample groups of equal size? Let's verify this by counting the number of users in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45db2827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>group</th>\n",
       "      <th>is_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8e27bf9a</td>\n",
       "      <td>A</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb89e6f0</td>\n",
       "      <td>A</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7119106a</td>\n",
       "      <td>A</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e53781ff</td>\n",
       "      <td>A</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02d48cf1</td>\n",
       "      <td>A</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id group is_purchase\n",
       "0  8e27bf9a     A          No\n",
       "1  eb89e6f0     A          No\n",
       "2  7119106a     A          No\n",
       "3  e53781ff     A          No\n",
       "4  02d48cf1     A         Yes"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, binomtest\n",
    "\n",
    "# Load data\n",
    "abdata = pd.read_csv('clicks.csv')\n",
    "\n",
    "# Preview data\n",
    "abdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a74569b",
   "metadata": {},
   "source": [
    "First, I will inspect the balance of the groups to ensure even distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e7357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    1666\n",
       "B    1666\n",
       "C    1666\n",
       "Name: group, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abdata['group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f2696",
   "metadata": {},
   "source": [
    "## 2. Chi-Square Test of Independence \n",
    "\n",
    "My null hypothesis is that there is no association between group assignment and purchase likelihood, i.e., the purchase rates are the same in all groups. The alternative hypothesis is that there is an association, i.e., the purchase rate in at least one group is different from the others.\n",
    "\n",
    "I will save the p-value from the Chi-square test in a variable named pval and print the result. I will use a significance threshold (α) of 0.05 to decide whether to reject the null hypothesis.\n",
    "\n",
    "If the p-value ≤ 0.05, I will reject the null hypothesis and conclude that there is a significant difference in the purchase rate across the groups. If the p-value > 0.05, I will not reject the null hypothesis and conclude that there is not enough evidence to suggest a difference in purchase rates.\n",
    "\n",
    "> Note: I will use the pd.crosstab() function to generate this table, and the chi2_contingency() function from the scipy.stats module to perform the Chi-square test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d60e6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 2.4126213546684264e-35, Significant? Yes\n"
     ]
    }
   ],
   "source": [
    "# Create contingency table\n",
    "Xtab = pd.crosstab(abdata['group'], abdata['is_purchase'])\n",
    "\n",
    "# Chi-square test of independence\n",
    "chi2, p_val, dof, expected = chi2_contingency(Xtab)\n",
    "\n",
    "# Print result\n",
    "print(f\"p-value = {p_val}, Significant? {'Yes' if p_val < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39cd9c2",
   "metadata": {},
   "source": [
    "**The p-value of 2.4126213546684264e-35 is extremely small, thus I can conclude that there is a significant difference between the purchase rate for each group.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fcb322",
   "metadata": {},
   "source": [
    "## 3. Reporintg Back to Brian\n",
    "\n",
    "After concluding the Chi-square test, I decided to discuss my findings with our stakeholder, Brian.\n",
    "\n",
    "Our Conversation with Brian:\n",
    "\n",
    "Me: *\"Hi Brian, can you tell me more about the test you were running?\"*\n",
    "\n",
    "Brian: *\"Sure, we are attempting to encourage users to purchase a small FarmBurg upgrade package. It's referred to as a microtransaction. We're unsure about the optimal pricing for it, so we've tested three different price points: \\\\$0.99 for group 'A', \\\\$1.99 for group 'B', and \\\\$4.99 for group 'C'. From our tests, it appears that significantly more people bought the upgrade package at \\\\$0.99, so that's the price we're considering.\"*\n",
    "\n",
    "> #### **It seems I acted too soon with the Chi-Square test.** It wasn't necessarily the best fit for this problem. \n",
    "While it's true that more people might be inclined to purchase the upgrade at $0.99, this doesn't necessarily equate to higher revenue. What I really need to determine is whether each price point will generate enough revenue to meet Brians target. \n",
    "\n",
    "Me: *\"Brian, do you have an idea of how much revenue you'd need to generate to justify this feature?\"*\n",
    "\n",
    "Brian: *\"I'd estimate that we'd need to make a minimum of $1000 per week from this feature to justify its development and maintenance.\"*\n",
    "\n",
    "### That gives me a clearer target to aim for.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Calculating Purchase Rates and Revenues\n",
    "\n",
    "To justify the cost of this feature, I must calculate the necessary purchase rate at each price point. Starting with the total weekly visitors on the site, we know Brian ran his original test over a week, implying the number of visitors in our dataset represents a typical week's visitor count.\n",
    "\n",
    "First, I will calculate the total number of site visitors from the data and save the value in a variable named `num_visits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eec8034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4998\n"
     ]
    }
   ],
   "source": [
    "num_visits = len(abdata)\n",
    "print(num_visits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7885b1",
   "metadata": {},
   "source": [
    "I know the number of weekly visitors (`num_visits`). Now, I need to calculate the number of visitors who would need to purchase the upgrade package at each price point (\\\\$0.99, \\\\$1.99, \\\\$4.99) to generate Brian’s minimum revenue target of \\\\$1,000 per week.\n",
    "\n",
    "Let's calculate the number of sales that would be needed to reach \\\\$1,000 of revenue at each price point and print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93cf014c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1011.0, 503.0, 201.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 1000\n",
    "num_sales_needed_099 = np.ceil(target/0.99)\n",
    "num_sales_needed_199 = np.ceil(target/1.99)\n",
    "num_sales_needed_499 = np.ceil(target/4.99)\n",
    "\n",
    "num_sales_needed_099,num_sales_needed_199,num_sales_needed_499"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f270be",
   "metadata": {},
   "source": [
    "Knowing the required number of sales, I can calculate the proportion of weekly visitors who would need to make a purchase in order to meet that goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22764924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of weekly visitors to break even if Brian prices the product at $0.99 is 0.20228091236494597\n",
      "The proportion of weekly visitors to break even if Brian prices the product at $1.99 is 0.10064025610244097\n",
      "The proportion of weekly visitors to break even if Brian prices the product at $4.99 is 0.040216086434573826\n"
     ]
    }
   ],
   "source": [
    "p_sales_needed_099 = num_sales_needed_099/num_visits\n",
    "p_sales_needed_199 = num_sales_needed_199/num_visits\n",
    "p_sales_needed_499 = num_sales_needed_499/num_visits\n",
    "\n",
    "print(f\"The proportion of weekly visitors to break even if Brian prices the product at $0.99 is {p_sales_needed_099}\")\n",
    "print(f\"The proportion of weekly visitors to break even if Brian prices the product at $1.99 is {p_sales_needed_199}\")\n",
    "print(f\"The proportion of weekly visitors to break even if Brian prices the product at $4.99 is {p_sales_needed_499}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add8006",
   "metadata": {},
   "source": [
    "Now I am ready to revisit Brian's question. \n",
    "\n",
    "I wants to know if the percent of any Group A/B/C, that purchased an upgrade, is significantly greater than the proportion of weekly visitors needed to achieve \\\\$1000 in revenue per week - measure by `p_sales_needed_099`. To answer this, I can focus on just the visitors in group A, and compare the number of purchases to `p_sales_needed_099`. And then repeat for the following two Groups.\n",
    "\n",
    "Given this scenario, a suitable test to analyze the purchase rates for each price point group is a binomial test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a28a5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinomTestResult(k=316, n=1666, alternative='greater', statistic=0.18967587034813926, pvalue=0.9058887362654593)\n",
      "BinomTestResult(k=183, n=1666, alternative='greater', statistic=0.10984393757503001, pvalue=0.11441815431122217)\n",
      "BinomTestResult(k=83, n=1666, alternative='greater', statistic=0.04981992797118848, pvalue=0.029642608610084057)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binomtest\n",
    "\n",
    "# Perform binomial test for group A ($0.99)\n",
    "samp_size_099 = Xtab.loc['A']['No'] + Xtab.loc['A']['Yes']\n",
    "sales_099 = Xtab.loc['A']['Yes']\n",
    "pvalueA = binomtest(sales_099,samp_size_099,p_sales_needed_099,'greater')\n",
    "\n",
    "# Perform binomial test for group B ($1.99)\n",
    "samp_size_199 = Xtab.loc['B']['No'] + Xtab.loc['B']['Yes']\n",
    "sales_199 = Xtab.loc['B']['Yes']\n",
    "pvalueB = binomtest(sales_199,samp_size_199,p_sales_needed_199,'greater')\n",
    "\n",
    "# Perform binomial test for group C ($4.99)\n",
    "samp_size_499 = Xtab.loc['C']['No'] + Xtab.loc['C']['Yes']\n",
    "sales_499 = Xtab.loc['C']['Yes']\n",
    "pvalueC = binomtest(sales_499,samp_size_499,p_sales_needed_499,'greater')\n",
    "\n",
    "# Print the p-values\n",
    "print(pvalueA)\n",
    "print(pvalueB)\n",
    "print(pvalueC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2d8bd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinomTestResult(k=316, n=1666, alternative='greater', statistic=0.18967587034813926, pvalue=0.9058887362654593)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalueA = binomtest(sales_099,samp_size_099,p_sales_needed_099,'greater')\n",
    "pvalueA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15198923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinomTestResult(k=183, n=1666, alternative='greater', statistic=0.10984393757503001, pvalue=0.11441815431122217)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalueB = binomtest(sales_199,samp_size_199,p_sales_needed_199,'greater')\n",
    "pvalueB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a90f34d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinomTestResult(k=83, n=1666, alternative='greater', statistic=0.04981992797118848, pvalue=0.029642608610084057)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalueC = binomtest(sales_499,samp_size_499,p_sales_needed_499,'greater')\n",
    "pvalueC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558029a6",
   "metadata": {},
   "source": [
    "## 5. Final Recommendation\n",
    "\n",
    "Based on the results of the binomial tests conducted for each price point group and considering a significance threshold of 0.05, I can determine the suitable price for Brian to charge for the upgrade package.\n",
    "\n",
    "My recommendation:\n",
    "\n",
    "Among the three price points tested, only the \\\\$4.99 price point (Group C) shows a significantly higher purchase rate compared to the target. This suggests that setting the price at \\\\$4.99 would be the most profitable option for Brian.\n",
    "\n",
    "**Therefore, I recommend Brian to charge \\\\$4.99 for the upgrade package based on the observed sales rate and the goal of generating sufficient revenue.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
